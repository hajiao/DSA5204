{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e047a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:51:37.862493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-01 15:51:37.939417: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d0948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtfevent(filepath):\n",
    "    ea=event_accumulator.EventAccumulator(filepath,size_guidance=event_accumulator.STORE_EVERYTHING_SIZE_GUIDANCE) \n",
    "    ea.Reload()\n",
    "    keys=ea.Tags()['tensors']\n",
    "    if len(keys)==0:\n",
    "        return pd.DataFrame()\n",
    "    tensors=ea.tensors\n",
    "    df=pd.DataFrame()\n",
    "    lists=[tensors.Items(key) for key in keys]\n",
    "    length=len(lists[0])\n",
    "    for i in range(length):\n",
    "        datas=[]\n",
    "        step=lists[0][i].step\n",
    "        walltime=lists[0][i].wall_time\n",
    "        for l in lists:\n",
    "            tmp=tf.make_ndarray(l[i].tensor_proto)\n",
    "            datas.append(np.nan if tmp.size==0 else tmp)\n",
    "        datas=np.array(datas)[None,:]\n",
    "        dfi=pd.DataFrame(datas,columns=keys)\n",
    "        dfi['step']=step\n",
    "        dfi['walltime']=walltime\n",
    "        df=pd.concat([df,dfi],ignore_index=True,)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad4534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadevents(log_path):\n",
    "    log_list=os.listdir(log_path)\n",
    "    df=pd.DataFrame()\n",
    "    for log in log_list:\n",
    "        dfi=loadtfevent(os.path.join(log_path,log))\n",
    "        df=pd.concat([df,dfi],ignore_index=True,)\n",
    "    return df\n",
    "def loaddatas(model_path):\n",
    "    model_list=os.listdir(model_path)\n",
    "    regex=f'.*logs.*'\n",
    "    var_match=re.compile(regex)\n",
    "    datas={}\n",
    "    for i,m in enumerate(model_list):\n",
    "        ret=var_match.match(m)\n",
    "        if ret:\n",
    "            datas[m]={}\n",
    "            if os.path.exists(os.path.join(model_path,m,'train')):\n",
    "                datas[m]['train']=loadevents(os.path.join(model_path,m,'train'))\n",
    "            if os.path.exists(os.path.join(model_path,m,'validation')):\n",
    "                datas[m]['validation']=loadevents(os.path.join(model_path,m,'validation'))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe90ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3', '0', 'train', '1', '4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './saved_model'\n",
    "model_lists=os.listdir(model_path)\n",
    "for file in ['chief','.ipynb_checkpoints','data.npz',]:\n",
    "    model_lists.remove(file)\n",
    "datasets={}\n",
    "model_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af7e3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unprogressive\n",
      "ground\n",
      "ground_progressive\n",
      "progressive_extended2\n",
      "progressive_concave\n",
      "progressive\n",
      "progressive_convex\n",
      "progressive_extended\n"
     ]
    }
   ],
   "source": [
    "for model in model_lists:\n",
    "    print(model)\n",
    "    datasets[model]=loadtfevent(os.path.join(model_path,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73ca6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('log_data.npy',datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a299228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_alldata(data_path):\n",
    "    datas={}\n",
    "    regex=f'^events\\.out\\.tfevents\\..*\\.v2$'\n",
    "    var_match=re.compile(regex)\n",
    "    for path,file_dir,files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            ret=var_match.match(file)\n",
    "            if ret:\n",
    "                print(os.path.join(path,file))\n",
    "                datas[path]=loadtfevent(os.path.join(path,file))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b86fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./automl/logs/2/execution0/events.out.tfevents.1680102918.SMC.2681602.6.v2\n",
      "./automl/logs/7/execution0/events.out.tfevents.1680239104.SMC.2681602.20.v2\n",
      "./automl/logs/7/execution0/validation/events.out.tfevents.1680239574.SMC.2681602.22.v2\n",
      "./automl/logs/7/execution0/train/events.out.tfevents.1680239113.SMC.2681602.21.v2\n",
      "./automl/logs/6/execution0/events.out.tfevents.1680211996.SMC.2681602.17.v2\n",
      "./automl/logs/6/execution0/validation/events.out.tfevents.1680212557.SMC.2681602.19.v2\n",
      "./automl/logs/6/execution0/train/events.out.tfevents.1680212003.SMC.2681602.18.v2\n",
      "./automl/logs/5/execution0/events.out.tfevents.1680186895.SMC.2681602.14.v2\n",
      "./automl/logs/5/execution0/validation/events.out.tfevents.1680187445.SMC.2681602.16.v2\n",
      "./automl/logs/5/execution0/train/events.out.tfevents.1680186898.SMC.2681602.15.v2\n",
      "./automl/logs/3/execution0/events.out.tfevents.1680102925.SMC.2681602.7.v2\n",
      "./automl/logs/3/execution0/validation/events.out.tfevents.1680103769.SMC.2681602.9.v2\n",
      "./automl/logs/3/execution0/train/events.out.tfevents.1680102929.SMC.2681602.8.v2\n",
      "./automl/logs/0/execution0/events.out.tfevents.1680077740.SMC.2681602.0.v2\n",
      "./automl/logs/0/execution0/validation/events.out.tfevents.1680077745.SMC.2681602.2.v2\n",
      "./automl/logs/0/execution0/train/events.out.tfevents.1680077743.SMC.2681602.1.v2\n",
      "./automl/logs/train/events.out.tfevents.1680261438.SMC.2681602.23.v2\n",
      "./automl/logs/train/events.out.tfevents.1680123079.SMC.2681602.13.v2\n",
      "./automl/logs/1/execution0/events.out.tfevents.1680077805.SMC.2681602.3.v2\n",
      "./automl/logs/1/execution0/validation/events.out.tfevents.1680078311.SMC.2681602.5.v2\n",
      "./automl/logs/1/execution0/train/events.out.tfevents.1680077810.SMC.2681602.4.v2\n",
      "./automl/logs/4/execution0/events.out.tfevents.1680113988.SMC.2681602.10.v2\n",
      "./automl/logs/4/execution0/validation/events.out.tfevents.1680114429.SMC.2681602.12.v2\n",
      "./automl/logs/4/execution0/train/events.out.tfevents.1680113992.SMC.2681602.11.v2\n"
     ]
    }
   ],
   "source": [
    "automldata=subtract_alldata('./automl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88d6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('log_automl.npy',automldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53e5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
